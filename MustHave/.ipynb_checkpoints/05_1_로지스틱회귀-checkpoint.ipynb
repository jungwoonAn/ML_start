{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀\n",
    "학습시간 대비 합격 불합격 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 (공부 시간)와 라벨 (합격: 1, 불합격: 0)\n",
    "x = np.array([2, 4,  6, 8, 10])  # 공부 시간\n",
    "y = np.array([0, 0,  1, 1, 1 ])   # 합격 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치와 절편 초기화\n",
    "w = 0  # weight\n",
    "b = 0  # bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01  # 학습률\n",
    "n = len(x)\n",
    "epochs = 5000  # 에포크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931, w: 0.0180, b: 0.0010\n",
      "Epoch 100, Loss: 0.3057, w: 0.2135, b: -0.1216\n",
      "Epoch 200, Loss: 0.3154, w: 0.2356, b: -0.2641\n",
      "Epoch 300, Loss: 0.3255, w: 0.2568, b: -0.4014\n",
      "Epoch 400, Loss: 0.3357, w: 0.2775, b: -0.5337\n",
      "Epoch 500, Loss: 0.3458, w: 0.2977, b: -0.6613\n",
      "Epoch 600, Loss: 0.3560, w: 0.3173, b: -0.7843\n",
      "Epoch 700, Loss: 0.3662, w: 0.3364, b: -0.9029\n",
      "Epoch 800, Loss: 0.3762, w: 0.3549, b: -1.0174\n",
      "Epoch 900, Loss: 0.3863, w: 0.3729, b: -1.1280\n",
      "Epoch 1000, Loss: 0.3962, w: 0.3905, b: -1.2349\n",
      "Epoch 1100, Loss: 0.4061, w: 0.4076, b: -1.3382\n",
      "Epoch 1200, Loss: 0.4158, w: 0.4242, b: -1.4381\n",
      "Epoch 1300, Loss: 0.4255, w: 0.4404, b: -1.5349\n",
      "Epoch 1400, Loss: 0.4350, w: 0.4562, b: -1.6287\n",
      "Epoch 1500, Loss: 0.4444, w: 0.4716, b: -1.7196\n",
      "Epoch 1600, Loss: 0.4536, w: 0.4866, b: -1.8078\n",
      "Epoch 1700, Loss: 0.4628, w: 0.5013, b: -1.8934\n",
      "Epoch 1800, Loss: 0.4718, w: 0.5156, b: -1.9766\n",
      "Epoch 1900, Loss: 0.4807, w: 0.5295, b: -2.0575\n",
      "Epoch 2000, Loss: 0.4894, w: 0.5431, b: -2.1362\n",
      "Epoch 2100, Loss: 0.4980, w: 0.5565, b: -2.2128\n",
      "Epoch 2200, Loss: 0.5065, w: 0.5695, b: -2.2874\n",
      "Epoch 2300, Loss: 0.5149, w: 0.5822, b: -2.3602\n",
      "Epoch 2400, Loss: 0.5231, w: 0.5947, b: -2.4311\n",
      "Epoch 2500, Loss: 0.5312, w: 0.6069, b: -2.5004\n",
      "Epoch 2600, Loss: 0.5392, w: 0.6188, b: -2.5680\n",
      "Epoch 2700, Loss: 0.5470, w: 0.6306, b: -2.6340\n",
      "Epoch 2800, Loss: 0.5548, w: 0.6420, b: -2.6986\n",
      "Epoch 2900, Loss: 0.5624, w: 0.6533, b: -2.7617\n",
      "Epoch 3000, Loss: 0.5699, w: 0.6644, b: -2.8235\n",
      "Epoch 3100, Loss: 0.5774, w: 0.6752, b: -2.8840\n",
      "Epoch 3200, Loss: 0.5847, w: 0.6859, b: -2.9433\n",
      "Epoch 3300, Loss: 0.5919, w: 0.6963, b: -3.0014\n",
      "Epoch 3400, Loss: 0.5990, w: 0.7066, b: -3.0583\n",
      "Epoch 3500, Loss: 0.6060, w: 0.7167, b: -3.1141\n",
      "Epoch 3600, Loss: 0.6129, w: 0.7266, b: -3.1689\n",
      "Epoch 3700, Loss: 0.6197, w: 0.7364, b: -3.2227\n",
      "Epoch 3800, Loss: 0.6264, w: 0.7460, b: -3.2755\n",
      "Epoch 3900, Loss: 0.6330, w: 0.7554, b: -3.3274\n",
      "Epoch 4000, Loss: 0.6395, w: 0.7647, b: -3.3784\n",
      "Epoch 4100, Loss: 0.6460, w: 0.7739, b: -3.4285\n",
      "Epoch 4200, Loss: 0.6524, w: 0.7829, b: -3.4777\n",
      "Epoch 4300, Loss: 0.6587, w: 0.7918, b: -3.5262\n",
      "Epoch 4400, Loss: 0.6649, w: 0.8006, b: -3.5739\n",
      "Epoch 4500, Loss: 0.6710, w: 0.8092, b: -3.6209\n",
      "Epoch 4600, Loss: 0.6771, w: 0.8178, b: -3.6671\n",
      "Epoch 4700, Loss: 0.6830, w: 0.8262, b: -3.7126\n",
      "Epoch 4800, Loss: 0.6890, w: 0.8345, b: -3.7575\n",
      "Epoch 4900, Loss: 0.6948, w: 0.8426, b: -3.8017\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀 학습\n",
    "for i in range(epochs):\n",
    "    # 예측값 계산\n",
    "    z = w*x + b\n",
    "    # 예측 함수(시그모이드)\n",
    "    y_pred = sigmoid(z)\n",
    "\n",
    "    # 오차 계산\n",
    "    error = y_pred - y\n",
    "    \n",
    "    # 경사 계산\n",
    "    w_diff = (1/n) * np.sum(x * error)\n",
    "    b_diff = (1/n) * np.sum(error)\n",
    "\n",
    "    # 가중치와 절편 업데이트\n",
    "    w = w - lr * w_diff\n",
    "    b = b - lr * b_diff\n",
    "\n",
    "    # 100 에폭마다 손실 출력\n",
    "    if i % 100 == 0:\n",
    "        # cross entropy error\n",
    "        loss = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 * y_pred))\n",
    "        print(f\"Epoch {i}, Loss: {loss:.4f}, w: {w:.4f}, b: {b:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 w: 0.8506, b: -3.8448\n",
      "정답 : [0 0 1 1 1]\n",
      "예측 :  [0.10495701 0.39120882 0.77882863 0.9507312  0.99063185]\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델 출력\n",
    "print(f\"최종 w: {w:.4f}, b: {b:.4f}\")   \n",
    "\n",
    "print('정답 :' ,y)\n",
    "print('예측 : ', y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
